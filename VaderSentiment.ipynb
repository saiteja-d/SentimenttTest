{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/danc/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "# DataFrame\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords \n",
    "# stopwords_english = stopwords.words('english')\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sentiment','id','date','query_string','user','text']\n",
    "df_test = pd.read_csv(\"/Users/danc/Downloads/labelled data/std140/testdata.manual.2009.06.14.csv\",encoding = \"ISO-8859-1\", header=None, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  id                          date query_string      user  \\\n",
       "0          4   3  Mon May 11 03:17:40 UTC 2009      kindle2    tpryan   \n",
       "1          4   4  Mon May 11 03:18:03 UTC 2009      kindle2    vcu451   \n",
       "2          4   5  Mon May 11 03:18:54 UTC 2009      kindle2    chadfu   \n",
       "3          4   6  Mon May 11 03:19:04 UTC 2009      kindle2     SIX15   \n",
       "4          4   7  Mon May 11 03:21:41 UTC 2009      kindle2  yamarama   \n",
       "\n",
       "                                                text  \n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...  \n",
       "1  Reading my kindle2...  Love it... Lee childs i...  \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "3  @kenburbary You'll love your Kindle2. I've had...  \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "# stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\", ' ', str(text).lower()).strip()    \n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['cleaned_text'] = df_test.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>loooooooovvvvvveee kindle2 dx cool 2 fantastic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>reading kindle2 love lee childs good read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>ok first assesment kindle2 fucking rocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>love kindle2 mine months never looked back new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>fair enough kindle2 think perfect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  id                          date query_string      user  \\\n",
       "0          4   3  Mon May 11 03:17:40 UTC 2009      kindle2    tpryan   \n",
       "1          4   4  Mon May 11 03:18:03 UTC 2009      kindle2    vcu451   \n",
       "2          4   5  Mon May 11 03:18:54 UTC 2009      kindle2    chadfu   \n",
       "3          4   6  Mon May 11 03:19:04 UTC 2009      kindle2     SIX15   \n",
       "4          4   7  Mon May 11 03:21:41 UTC 2009      kindle2  yamarama   \n",
       "\n",
       "                                                text  \\\n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...   \n",
       "1  Reading my kindle2...  Love it... Lee childs i...   \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...   \n",
       "3  @kenburbary You'll love your Kindle2. I've had...   \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  loooooooovvvvvveee kindle2 dx cool 2 fantastic...  \n",
       "1          reading kindle2 love lee childs good read  \n",
       "2           ok first assesment kindle2 fucking rocks  \n",
       "3  love kindle2 mine months never looked back new...  \n",
       "4                  fair enough kindle2 think perfect  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['id','date','query_string'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = df_test['cleaned_text']\n",
    "all_sent_values = []\n",
    "all_sentiments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "def sentiment_value(paragraph):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    result = analyser.polarity_scores(paragraph)\n",
    "    return result\n",
    "#     score = result['compound']\n",
    "#     return round(score,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love kindle2 stacks books trip way loo\n",
      "Sentiment: \n",
      "{'neg': 0.0, 'neu': 0.588, 'pos': 0.412, 'compound': 0.6369}\n"
     ]
    }
   ],
   "source": [
    "sample = df_test['cleaned_text'][456]\n",
    "print(sample)\n",
    "print('Sentiment: ')\n",
    "print(sentiment_value(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df_test)):\n",
    "    all_sent_values.append(sentiment_value(all_reviews[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['all_dict'] = all_sent_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>all_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>loooooooovvvvvveee kindle2 dx cool 2 fantastic...</td>\n",
       "      <td>{'neg': 0.31, 'neu': 0.233, 'pos': 0.457, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>reading kindle2 love lee childs good read</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.413, 'pos': 0.587, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>ok first assesment kindle2 fucking rocks</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.694, 'pos': 0.306, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>love kindle2 mine months never looked back new...</td>\n",
       "      <td>{'neg': 0.113, 'neu': 0.538, 'pos': 0.349, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>fair enough kindle2 think perfect</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.333, 'pos': 0.667, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  id                          date query_string      user  \\\n",
       "0          4   3  Mon May 11 03:17:40 UTC 2009      kindle2    tpryan   \n",
       "1          4   4  Mon May 11 03:18:03 UTC 2009      kindle2    vcu451   \n",
       "2          4   5  Mon May 11 03:18:54 UTC 2009      kindle2    chadfu   \n",
       "3          4   6  Mon May 11 03:19:04 UTC 2009      kindle2     SIX15   \n",
       "4          4   7  Mon May 11 03:21:41 UTC 2009      kindle2  yamarama   \n",
       "\n",
       "                                                text  \\\n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...   \n",
       "1  Reading my kindle2...  Love it... Lee childs i...   \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...   \n",
       "3  @kenburbary You'll love your Kindle2. I've had...   \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  loooooooovvvvvveee kindle2 dx cool 2 fantastic...   \n",
       "1          reading kindle2 love lee childs good read   \n",
       "2           ok first assesment kindle2 fucking rocks   \n",
       "3  love kindle2 mine months never looked back new...   \n",
       "4                  fair enough kindle2 think perfect   \n",
       "\n",
       "                                            all_dict  \n",
       "0  {'neg': 0.31, 'neu': 0.233, 'pos': 0.457, 'com...  \n",
       "1  {'neg': 0.0, 'neu': 0.413, 'pos': 0.587, 'comp...  \n",
       "2  {'neg': 0.0, 'neu': 0.694, 'pos': 0.306, 'comp...  \n",
       "3  {'neg': 0.113, 'neu': 0.538, 'pos': 0.349, 'co...  \n",
       "4  {'neg': 0.0, 'neu': 0.333, 'pos': 0.667, 'comp...  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTIMENT_VALUE = []\n",
    "# SENTIMENT = []\n",
    "# for i in range(0,len(df_test)):\n",
    "#     sent = all_sent_values[i]['compound']\n",
    "#     if (sent<=1 and sent>=0.5):\n",
    "#         SENTIMENT.append('V.Positive')\n",
    "#         SENTIMENT_VALUE.append(5)\n",
    "#     elif (sent<0.5 and sent>0):\n",
    "#         SENTIMENT.append('Positive')\n",
    "#         SENTIMENT_VALUE.append(4)\n",
    "#     elif (sent==0):\n",
    "#         SENTIMENT.append('Neutral')\n",
    "#         SENTIMENT_VALUE.append(3)\n",
    "#     elif (sent<0 and sent>=-0.5):\n",
    "#         SENTIMENT.append('Negative')\n",
    "#         SENTIMENT_VALUE.append(2)\n",
    "#     else:\n",
    "#         SENTIMENT.append('V.Negative')\n",
    "#         SENTIMENT_VALUE.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_VALUE = []\n",
    "SENTIMENT = []\n",
    "for i in range(0,len(df_test)):\n",
    "    sent = all_sent_values[i]['compound']\n",
    "    if (sent<=1 and sent>0):\n",
    "        SENTIMENT.append('Positive')\n",
    "        SENTIMENT_VALUE.append(4)\n",
    "    elif (sent==0):\n",
    "        SENTIMENT.append('Neutral')\n",
    "        SENTIMENT_VALUE.append(2)\n",
    "    else:\n",
    "        SENTIMENT.append('Negative')\n",
    "        SENTIMENT_VALUE.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sent_values[4]['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['SENTIMENT_VALUE'] = SENTIMENT_VALUE\n",
    "df_test['SENTIMENT'] = SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>all_dict</th>\n",
       "      <th>SENTIMENT_VALUE</th>\n",
       "      <th>SENTIMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>loooooooovvvvvveee kindle2 dx cool 2 fantastic...</td>\n",
       "      <td>{'neg': 0.31, 'neu': 0.233, 'pos': 0.457, 'com...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>reading kindle2 love lee childs good read</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.413, 'pos': 0.587, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>ok first assesment kindle2 fucking rocks</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.694, 'pos': 0.306, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>love kindle2 mine months never looked back new...</td>\n",
       "      <td>{'neg': 0.113, 'neu': 0.538, 'pos': 0.349, 'co...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>fair enough kindle2 think perfect</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.333, 'pos': 0.667, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "      <td>big quite happy kindle2</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.429, 'pos': 0.571, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>Mon May 11 03:22:30 UTC 2009</td>\n",
       "      <td>aig</td>\n",
       "      <td>Seth937</td>\n",
       "      <td>Fuck this economy. I hate aig and their non lo...</td>\n",
       "      <td>fuck economy hate aig non loan given asses</td>\n",
       "      <td>{'neg': 0.545, 'neu': 0.455, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon May 11 03:26:10 UTC 2009</td>\n",
       "      <td>jquery</td>\n",
       "      <td>dcostalis</td>\n",
       "      <td>Jquery is my new best friend.</td>\n",
       "      <td>jquery new best friend</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.213, 'pos': 0.787, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Mon May 11 03:27:15 UTC 2009</td>\n",
       "      <td>twitter</td>\n",
       "      <td>PJ_King</td>\n",
       "      <td>Loves twitter</td>\n",
       "      <td>loves twitter</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.213, 'pos': 0.787, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Mon May 11 03:29:20 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>mandanicole</td>\n",
       "      <td>how can you not love Obama? he makes jokes abo...</td>\n",
       "      <td>love obama makes jokes</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.244, 'pos': 0.756, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>Mon May 11 03:32:42 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>jpeb</td>\n",
       "      <td>Check this video out -- President Obama at the...</td>\n",
       "      <td>check video president obama white house corres...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Mon May 11 03:32:48 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>kylesellers</td>\n",
       "      <td>@Karoli I firmly believe that Obama/Pelosi hav...</td>\n",
       "      <td>firmly believe obama pelosi zero desire civil ...</td>\n",
       "      <td>{'neg': 0.212, 'neu': 0.545, 'pos': 0.242, 'co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>Mon May 11 03:33:38 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>theviewfans</td>\n",
       "      <td>House Correspondents dinner was last night who...</td>\n",
       "      <td>house correspondents dinner last night whoopi ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>Mon May 11 05:05:58 UTC 2009</td>\n",
       "      <td>nike</td>\n",
       "      <td>MumsFP</td>\n",
       "      <td>Watchin Espn..Jus seen this new Nike Commerica...</td>\n",
       "      <td>watchin espn jus seen new nike commerical pupp...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.602, 'pos': 0.398, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Mon May 11 05:06:22 UTC 2009</td>\n",
       "      <td>nike</td>\n",
       "      <td>vincentx24x</td>\n",
       "      <td>dear nike, stop with the flywire. that shit is...</td>\n",
       "      <td>dear nike stop flywire shit waste science ugly...</td>\n",
       "      <td>{'neg': 0.524, 'neu': 0.176, 'pos': 0.3, 'comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>Mon May 11 05:20:15 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>cameronwylie</td>\n",
       "      <td>#lebron best athlete of our generation, if not...</td>\n",
       "      <td>lebron best athlete generation time basketball...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.645, 'pos': 0.355, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>Mon May 11 05:20:28 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>luv8242</td>\n",
       "      <td>I was talking to this guy last night and he wa...</td>\n",
       "      <td>talking guy last night telling die hard spurs ...</td>\n",
       "      <td>{'neg': 0.4, 'neu': 0.488, 'pos': 0.112, 'comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>Mon May 11 05:21:04 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>mtgillikin</td>\n",
       "      <td>i love lebron. http://bit.ly/PdHur</td>\n",
       "      <td>love lebron</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Mon May 11 05:21:37 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>ursecretdezire</td>\n",
       "      <td>@ludajuice Lebron is a Beast, but I'm still ch...</td>\n",
       "      <td>lebron beast still cheering 4 til end</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.602, 'pos': 0.398, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>Mon May 11 05:21:45 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>Native_01</td>\n",
       "      <td>@Pmillzz lebron IS THE BOSS</td>\n",
       "      <td>lebron boss</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>Mon May 11 05:22:03 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>princezzcutz</td>\n",
       "      <td>@sketchbug Lebron is a hometown hero to me, lo...</td>\n",
       "      <td>lebron hometown hero lol love lakers let go ca...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.309, 'pos': 0.691, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>Mon May 11 05:22:12 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>peterlikewhat</td>\n",
       "      <td>lebron and zydrunas are such an awesome duo</td>\n",
       "      <td>lebron zydrunas awesome duo</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>Mon May 11 05:22:37 UTC 2009</td>\n",
       "      <td>lebron</td>\n",
       "      <td>emceet</td>\n",
       "      <td>@wordwhizkid Lebron is a beast... nobody in th...</td>\n",
       "      <td>lebron beast nobody nba comes even close</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>Mon May 11 06:02:24 UTC 2009</td>\n",
       "      <td>iphone app</td>\n",
       "      <td>CocoSavanna</td>\n",
       "      <td>downloading apps for my iphone! So much fun :-...</td>\n",
       "      <td>downloading apps iphone much fun literally app...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.68, 'pos': 0.32, 'compou...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>Mon May 11 19:47:29 UTC 2009</td>\n",
       "      <td>visa</td>\n",
       "      <td>DreambigRadio</td>\n",
       "      <td>good news, just had a call from the Visa offic...</td>\n",
       "      <td>good news call visa office saying everything f...</td>\n",
       "      <td>{'neg': 0.439, 'neu': 0.244, 'pos': 0.317, 'co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>Mon May 11 19:49:21 UTC 2009</td>\n",
       "      <td>fredwilson</td>\n",
       "      <td>andrewwatson</td>\n",
       "      <td>http://twurl.nl/epkr4b - awesome come back fro...</td>\n",
       "      <td>awesome come back biz via fredwilson</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.549, 'pos': 0.451, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>Mon May 11 19:50:07 UTC 2009</td>\n",
       "      <td>fredwilson</td>\n",
       "      <td>fredwilson</td>\n",
       "      <td>In montreal for a long weekend of R&amp;amp;R. Muc...</td>\n",
       "      <td>montreal long weekend r amp r much needed</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>Thu May 14 02:58:07 UTC 2009</td>\n",
       "      <td>\"booz allen\"</td>\n",
       "      <td>JoeSchueller</td>\n",
       "      <td>Booz Allen Hamilton has a bad ass homegrown so...</td>\n",
       "      <td>booz allen hamilton bad ass homegrown social c...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.552, 'pos': 0.448, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>Thu May 14 02:58:23 UTC 2009</td>\n",
       "      <td>\"booz allen\"</td>\n",
       "      <td>scottabel</td>\n",
       "      <td>[#MLUC09] Customer Innovation Award Winner: Bo...</td>\n",
       "      <td>mluc09 customer innovation award winner booz a...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.336, 'pos': 0.664, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>Thu May 14 05:24:50 UTC 2009</td>\n",
       "      <td>40d</td>\n",
       "      <td>JustMe_D</td>\n",
       "      <td>@SoChi2 I current use the Nikon D90 and love i...</td>\n",
       "      <td>current use nikon d90 love much canon 40d 50d ...</td>\n",
       "      <td>{'neg': 0.129, 'neu': 0.645, 'pos': 0.226, 'co...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0</td>\n",
       "      <td>2579</td>\n",
       "      <td>Tue Jun 09 05:53:40 UTC 2009</td>\n",
       "      <td>iphone app</td>\n",
       "      <td>Jesssssii</td>\n",
       "      <td>Man I kinda dislike Apple right now. Case in p...</td>\n",
       "      <td>man kinda dislike apple right case point iphon...</td>\n",
       "      <td>{'neg': 0.126, 'neu': 0.601, 'pos': 0.273, 'co...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>4</td>\n",
       "      <td>7011</td>\n",
       "      <td>Wed Jun 10 04:03:37 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>jimhong</td>\n",
       "      <td>@cwong08 I have a Kindle2 (&amp;amp; Sony PRS-500)...</td>\n",
       "      <td>kindle2 amp sony prs 500 like physical device ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>4</td>\n",
       "      <td>7012</td>\n",
       "      <td>Wed Jun 10 04:03:53 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>Ant_Ward</td>\n",
       "      <td>The #Kindle2 seems the best eReader, but will ...</td>\n",
       "      <td>kindle2 seems best ereader work uk get one</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>4</td>\n",
       "      <td>7015</td>\n",
       "      <td>Wed Jun 10 05:24:40 UTC 2009</td>\n",
       "      <td>google</td>\n",
       "      <td>popitlockit</td>\n",
       "      <td>I have a google addiction. Thank you for point...</td>\n",
       "      <td>google addiction thank pointing annamartin123 ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.396, 'pos': 0.604, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>2</td>\n",
       "      <td>7055</td>\n",
       "      <td>Wed Jun 10 15:31:56 UTC 2009</td>\n",
       "      <td>visa card</td>\n",
       "      <td>FionaSarah</td>\n",
       "      <td>@ruby_gem My primary debit card is Visa Electron.</td>\n",
       "      <td>primary debit card visa electron</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2</td>\n",
       "      <td>8051</td>\n",
       "      <td>Wed Jun 10 15:31:59 UTC 2009</td>\n",
       "      <td>visa card</td>\n",
       "      <td>MalloryRayne</td>\n",
       "      <td>Off to the bank to get my new visa platinum card</td>\n",
       "      <td>bank get new visa platinum card</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>8052</td>\n",
       "      <td>Wed Jun 10 15:32:06 UTC 2009</td>\n",
       "      <td>visa card</td>\n",
       "      <td>_abi_</td>\n",
       "      <td>dearest @google, you rich bastards! the VISA c...</td>\n",
       "      <td>dearest google rich bastards visa card sent wo...</td>\n",
       "      <td>{'neg': 0.247, 'neu': 0.321, 'pos': 0.432, 'co...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2</td>\n",
       "      <td>13051</td>\n",
       "      <td>Sat Jun 13 16:23:31 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>sfkerropi6</td>\n",
       "      <td>has a date with bobby flay and gut fieri from ...</td>\n",
       "      <td>date bobby flay gut fieri food network</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4</td>\n",
       "      <td>13052</td>\n",
       "      <td>Sat Jun 13 16:24:08 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>tessalau</td>\n",
       "      <td>Excited about seeing Bobby Flay and Guy Fieri ...</td>\n",
       "      <td>excited seeing bobby flay guy fieri tomorrow g...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.629, 'pos': 0.371, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>4</td>\n",
       "      <td>13053</td>\n",
       "      <td>Sat Jun 13 16:24:12 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>ZFilth</td>\n",
       "      <td>Gonna go see Bobby Flay 2moro at Shoreline. Ea...</td>\n",
       "      <td>gonna go see bobby flay 2moro shoreline eat dr...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.775, 'pos': 0.225, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>4</td>\n",
       "      <td>13054</td>\n",
       "      <td>Sat Jun 13 16:24:25 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>annieblane</td>\n",
       "      <td>can't wait for the great american food and mus...</td>\n",
       "      <td>wait great american food music festival shorel...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.472, 'pos': 0.528, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>4</td>\n",
       "      <td>13055</td>\n",
       "      <td>Sat Jun 13 16:24:34 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>LAURAcBRYAN</td>\n",
       "      <td>My dad was in NY for a day, we ate at MESA gri...</td>\n",
       "      <td>dad ny day ate mesa grill last night met bobby...</td>\n",
       "      <td>{'neg': 0.118, 'neu': 0.731, 'pos': 0.151, 'co...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0</td>\n",
       "      <td>13073</td>\n",
       "      <td>Sun Jun 14 04:35:33 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>NathanChalmers</td>\n",
       "      <td>Fighting with LaTex. Again...</td>\n",
       "      <td>fighting latex</td>\n",
       "      <td>{'neg': 0.714, 'neu': 0.286, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0</td>\n",
       "      <td>13074</td>\n",
       "      <td>Sun Jun 14 04:35:53 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>LoonyLongbottom</td>\n",
       "      <td>@Iheartseverus we love you too and don't want ...</td>\n",
       "      <td>love want die latex devil</td>\n",
       "      <td>{'neg': 0.561, 'neu': 0.068, 'pos': 0.372, 'co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>13075</td>\n",
       "      <td>Sun Jun 14 04:36:07 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>QuadError</td>\n",
       "      <td>7 hours. 7 hours of inkscape crashing, normall...</td>\n",
       "      <td>7 hours 7 hours inkscape crashing normally sol...</td>\n",
       "      <td>{'neg': 0.125, 'neu': 0.764, 'pos': 0.111, 'co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2</td>\n",
       "      <td>13076</td>\n",
       "      <td>Sun Jun 14 21:35:58 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>musicmuse</td>\n",
       "      <td>How to Track Iran with Social Media: http://bi...</td>\n",
       "      <td>track iran social media</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>13077</td>\n",
       "      <td>Sun Jun 14 21:36:04 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>sketoaks</td>\n",
       "      <td>Shit's hitting the fan in Iran...craziness ind...</td>\n",
       "      <td>shit hitting fan iran craziness indeed iranele...</td>\n",
       "      <td>{'neg': 0.496, 'neu': 0.32, 'pos': 0.184, 'com...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>13078</td>\n",
       "      <td>Sun Jun 14 21:36:09 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>jamespenycate</td>\n",
       "      <td>Monday already. Iran may implode. Kitchen is a...</td>\n",
       "      <td>monday already iran may implode kitchen disast...</td>\n",
       "      <td>{'neg': 0.154, 'neu': 0.449, 'pos': 0.397, 'co...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2</td>\n",
       "      <td>14045</td>\n",
       "      <td>Sat Jun 13 16:13:59 UTC 2009</td>\n",
       "      <td>aapl</td>\n",
       "      <td>boardcentral</td>\n",
       "      <td>Twitter Stock buzz: $AAPL $ES_F $SPY $SPX $PAL...</td>\n",
       "      <td>twitter stock buzz aapl es f spy spx palm upda...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4</td>\n",
       "      <td>14046</td>\n",
       "      <td>Sat Jun 13 16:23:41 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>JimFacey</td>\n",
       "      <td>getting ready to test out some burger receipes...</td>\n",
       "      <td>getting ready test burger receipes weekend bob...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>2</td>\n",
       "      <td>14049</td>\n",
       "      <td>Sat Jun 13 16:24:03 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>wetfishdesigns</td>\n",
       "      <td>@johncmayer is Bobby Flay joining you?</td>\n",
       "      <td>bobby flay joining</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>4</td>\n",
       "      <td>14050</td>\n",
       "      <td>Sat Jun 13 16:24:15 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>A_TALL_BLONDE</td>\n",
       "      <td>i lam so in love with Bobby Flay... he is my f...</td>\n",
       "      <td>lam love bobby flay favorite rt terrysimpson b...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.469, 'pos': 0.531, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>14069</td>\n",
       "      <td>Sun Jun 14 04:31:12 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>rooney_tunes</td>\n",
       "      <td>I just created my first LaTeX file from scratc...</td>\n",
       "      <td>created first latex file scratch work well see...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.523, 'pos': 0.477, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>4</td>\n",
       "      <td>14070</td>\n",
       "      <td>Sun Jun 14 04:31:23 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>roguemovement</td>\n",
       "      <td>using Linux and loving it - so much nicer than...</td>\n",
       "      <td>using linux loving much nicer windows looking ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.595, 'pos': 0.405, 'comp...</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>4</td>\n",
       "      <td>14071</td>\n",
       "      <td>Sun Jun 14 04:31:28 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>yomcat</td>\n",
       "      <td>After using LaTeX a lot, any other typeset mat...</td>\n",
       "      <td>using latex lot typeset mathematics looks hideous</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2</td>\n",
       "      <td>14072</td>\n",
       "      <td>Sun Jun 14 04:31:43 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>proggit</td>\n",
       "      <td>Ask Programming: LaTeX or InDesign?: submitted...</td>\n",
       "      <td>ask programming latex indesign submitted calci...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>14073</td>\n",
       "      <td>Sun Jun 14 04:32:17 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>sam33r</td>\n",
       "      <td>On that note, I hate Word. I hate Pages. I hat...</td>\n",
       "      <td>note hate word hate pages hate latex said hate...</td>\n",
       "      <td>{'neg': 0.709, 'neu': 0.291, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>14074</td>\n",
       "      <td>Sun Jun 14 04:36:34 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>iamtheonlyjosie</td>\n",
       "      <td>Ahhh... back in a *real* text editing environm...</td>\n",
       "      <td>ahhh back real text editing environment lt 3 l...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>14075</td>\n",
       "      <td>Sun Jun 14 21:36:07 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>plutopup7</td>\n",
       "      <td>Trouble in Iran, I see. Hmm. Iran. Iran so far...</td>\n",
       "      <td>trouble iran see hmm iran iran far away flocko...</td>\n",
       "      <td>{'neg': 0.252, 'neu': 0.748, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>14076</td>\n",
       "      <td>Sun Jun 14 21:36:17 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>captain_pete</td>\n",
       "      <td>Reading the tweets coming out of Iran... The w...</td>\n",
       "      <td>reading tweets coming iran whole thing terrify...</td>\n",
       "      <td>{'neg': 0.503, 'neu': 0.497, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment     id                          date  query_string  \\\n",
       "0            4      3  Mon May 11 03:17:40 UTC 2009       kindle2   \n",
       "1            4      4  Mon May 11 03:18:03 UTC 2009       kindle2   \n",
       "2            4      5  Mon May 11 03:18:54 UTC 2009       kindle2   \n",
       "3            4      6  Mon May 11 03:19:04 UTC 2009       kindle2   \n",
       "4            4      7  Mon May 11 03:21:41 UTC 2009       kindle2   \n",
       "5            4      8  Mon May 11 03:22:00 UTC 2009       kindle2   \n",
       "6            0      9  Mon May 11 03:22:30 UTC 2009           aig   \n",
       "7            4     10  Mon May 11 03:26:10 UTC 2009        jquery   \n",
       "8            4     11  Mon May 11 03:27:15 UTC 2009       twitter   \n",
       "9            4     12  Mon May 11 03:29:20 UTC 2009         obama   \n",
       "10           2     13  Mon May 11 03:32:42 UTC 2009         obama   \n",
       "11           0     14  Mon May 11 03:32:48 UTC 2009         obama   \n",
       "12           4     15  Mon May 11 03:33:38 UTC 2009         obama   \n",
       "13           4     16  Mon May 11 05:05:58 UTC 2009          nike   \n",
       "14           0     17  Mon May 11 05:06:22 UTC 2009          nike   \n",
       "15           4     18  Mon May 11 05:20:15 UTC 2009        lebron   \n",
       "16           0     19  Mon May 11 05:20:28 UTC 2009        lebron   \n",
       "17           4     20  Mon May 11 05:21:04 UTC 2009        lebron   \n",
       "18           0     21  Mon May 11 05:21:37 UTC 2009        lebron   \n",
       "19           4     22  Mon May 11 05:21:45 UTC 2009        lebron   \n",
       "20           4     23  Mon May 11 05:22:03 UTC 2009        lebron   \n",
       "21           4     24  Mon May 11 05:22:12 UTC 2009        lebron   \n",
       "22           4     25  Mon May 11 05:22:37 UTC 2009        lebron   \n",
       "23           4     26  Mon May 11 06:02:24 UTC 2009    iphone app   \n",
       "24           4     33  Mon May 11 19:47:29 UTC 2009          visa   \n",
       "25           4     34  Mon May 11 19:49:21 UTC 2009    fredwilson   \n",
       "26           4     35  Mon May 11 19:50:07 UTC 2009    fredwilson   \n",
       "27           4     46  Thu May 14 02:58:07 UTC 2009  \"booz allen\"   \n",
       "28           4     47  Thu May 14 02:58:23 UTC 2009  \"booz allen\"   \n",
       "29           4     49  Thu May 14 05:24:50 UTC 2009           40d   \n",
       "..         ...    ...                           ...           ...   \n",
       "468          0   2579  Tue Jun 09 05:53:40 UTC 2009    iphone app   \n",
       "469          4   7011  Wed Jun 10 04:03:37 UTC 2009       kindle2   \n",
       "470          4   7012  Wed Jun 10 04:03:53 UTC 2009       kindle2   \n",
       "471          4   7015  Wed Jun 10 05:24:40 UTC 2009        google   \n",
       "472          2   7055  Wed Jun 10 15:31:56 UTC 2009     visa card   \n",
       "473          2   8051  Wed Jun 10 15:31:59 UTC 2009     visa card   \n",
       "474          0   8052  Wed Jun 10 15:32:06 UTC 2009     visa card   \n",
       "475          2  13051  Sat Jun 13 16:23:31 UTC 2009    Bobby Flay   \n",
       "476          4  13052  Sat Jun 13 16:24:08 UTC 2009    Bobby Flay   \n",
       "477          4  13053  Sat Jun 13 16:24:12 UTC 2009    Bobby Flay   \n",
       "478          4  13054  Sat Jun 13 16:24:25 UTC 2009    Bobby Flay   \n",
       "479          4  13055  Sat Jun 13 16:24:34 UTC 2009    Bobby Flay   \n",
       "480          0  13073  Sun Jun 14 04:35:33 UTC 2009         latex   \n",
       "481          0  13074  Sun Jun 14 04:35:53 UTC 2009         latex   \n",
       "482          0  13075  Sun Jun 14 04:36:07 UTC 2009         latex   \n",
       "483          2  13076  Sun Jun 14 21:35:58 UTC 2009          iran   \n",
       "484          0  13077  Sun Jun 14 21:36:04 UTC 2009          iran   \n",
       "485          0  13078  Sun Jun 14 21:36:09 UTC 2009          iran   \n",
       "486          2  14045  Sat Jun 13 16:13:59 UTC 2009          aapl   \n",
       "487          4  14046  Sat Jun 13 16:23:41 UTC 2009    Bobby Flay   \n",
       "488          2  14049  Sat Jun 13 16:24:03 UTC 2009    Bobby Flay   \n",
       "489          4  14050  Sat Jun 13 16:24:15 UTC 2009    Bobby Flay   \n",
       "490          0  14069  Sun Jun 14 04:31:12 UTC 2009         latex   \n",
       "491          4  14070  Sun Jun 14 04:31:23 UTC 2009         latex   \n",
       "492          4  14071  Sun Jun 14 04:31:28 UTC 2009         latex   \n",
       "493          2  14072  Sun Jun 14 04:31:43 UTC 2009         latex   \n",
       "494          0  14073  Sun Jun 14 04:32:17 UTC 2009         latex   \n",
       "495          4  14074  Sun Jun 14 04:36:34 UTC 2009         latex   \n",
       "496          0  14075  Sun Jun 14 21:36:07 UTC 2009          iran   \n",
       "497          0  14076  Sun Jun 14 21:36:17 UTC 2009          iran   \n",
       "\n",
       "                user                                               text  \\\n",
       "0             tpryan  @stellargirl I loooooooovvvvvveee my Kindle2. ...   \n",
       "1             vcu451  Reading my kindle2...  Love it... Lee childs i...   \n",
       "2             chadfu  Ok, first assesment of the #kindle2 ...it fuck...   \n",
       "3              SIX15  @kenburbary You'll love your Kindle2. I've had...   \n",
       "4           yamarama  @mikefish  Fair enough. But i have the Kindle2...   \n",
       "5       GeorgeVHulme  @richardebaker no. it is too big. I'm quite ha...   \n",
       "6            Seth937  Fuck this economy. I hate aig and their non lo...   \n",
       "7          dcostalis                      Jquery is my new best friend.   \n",
       "8            PJ_King                                      Loves twitter   \n",
       "9        mandanicole  how can you not love Obama? he makes jokes abo...   \n",
       "10              jpeb  Check this video out -- President Obama at the...   \n",
       "11       kylesellers  @Karoli I firmly believe that Obama/Pelosi hav...   \n",
       "12       theviewfans  House Correspondents dinner was last night who...   \n",
       "13            MumsFP  Watchin Espn..Jus seen this new Nike Commerica...   \n",
       "14       vincentx24x  dear nike, stop with the flywire. that shit is...   \n",
       "15      cameronwylie  #lebron best athlete of our generation, if not...   \n",
       "16           luv8242  I was talking to this guy last night and he wa...   \n",
       "17        mtgillikin                 i love lebron. http://bit.ly/PdHur   \n",
       "18    ursecretdezire  @ludajuice Lebron is a Beast, but I'm still ch...   \n",
       "19         Native_01                        @Pmillzz lebron IS THE BOSS   \n",
       "20      princezzcutz  @sketchbug Lebron is a hometown hero to me, lo...   \n",
       "21     peterlikewhat        lebron and zydrunas are such an awesome duo   \n",
       "22            emceet  @wordwhizkid Lebron is a beast... nobody in th...   \n",
       "23       CocoSavanna  downloading apps for my iphone! So much fun :-...   \n",
       "24     DreambigRadio  good news, just had a call from the Visa offic...   \n",
       "25      andrewwatson  http://twurl.nl/epkr4b - awesome come back fro...   \n",
       "26        fredwilson  In montreal for a long weekend of R&amp;R. Muc...   \n",
       "27      JoeSchueller  Booz Allen Hamilton has a bad ass homegrown so...   \n",
       "28         scottabel  [#MLUC09] Customer Innovation Award Winner: Bo...   \n",
       "29          JustMe_D  @SoChi2 I current use the Nikon D90 and love i...   \n",
       "..               ...                                                ...   \n",
       "468        Jesssssii  Man I kinda dislike Apple right now. Case in p...   \n",
       "469          jimhong  @cwong08 I have a Kindle2 (&amp; Sony PRS-500)...   \n",
       "470         Ant_Ward  The #Kindle2 seems the best eReader, but will ...   \n",
       "471      popitlockit  I have a google addiction. Thank you for point...   \n",
       "472       FionaSarah  @ruby_gem My primary debit card is Visa Electron.   \n",
       "473     MalloryRayne   Off to the bank to get my new visa platinum card   \n",
       "474            _abi_  dearest @google, you rich bastards! the VISA c...   \n",
       "475       sfkerropi6  has a date with bobby flay and gut fieri from ...   \n",
       "476         tessalau  Excited about seeing Bobby Flay and Guy Fieri ...   \n",
       "477           ZFilth  Gonna go see Bobby Flay 2moro at Shoreline. Ea...   \n",
       "478       annieblane  can't wait for the great american food and mus...   \n",
       "479      LAURAcBRYAN  My dad was in NY for a day, we ate at MESA gri...   \n",
       "480   NathanChalmers                      Fighting with LaTex. Again...   \n",
       "481  LoonyLongbottom  @Iheartseverus we love you too and don't want ...   \n",
       "482        QuadError  7 hours. 7 hours of inkscape crashing, normall...   \n",
       "483        musicmuse  How to Track Iran with Social Media: http://bi...   \n",
       "484         sketoaks  Shit's hitting the fan in Iran...craziness ind...   \n",
       "485    jamespenycate  Monday already. Iran may implode. Kitchen is a...   \n",
       "486     boardcentral  Twitter Stock buzz: $AAPL $ES_F $SPY $SPX $PAL...   \n",
       "487         JimFacey  getting ready to test out some burger receipes...   \n",
       "488   wetfishdesigns             @johncmayer is Bobby Flay joining you?   \n",
       "489    A_TALL_BLONDE  i lam so in love with Bobby Flay... he is my f...   \n",
       "490     rooney_tunes  I just created my first LaTeX file from scratc...   \n",
       "491    roguemovement  using Linux and loving it - so much nicer than...   \n",
       "492           yomcat  After using LaTeX a lot, any other typeset mat...   \n",
       "493          proggit  Ask Programming: LaTeX or InDesign?: submitted...   \n",
       "494           sam33r  On that note, I hate Word. I hate Pages. I hat...   \n",
       "495  iamtheonlyjosie  Ahhh... back in a *real* text editing environm...   \n",
       "496        plutopup7  Trouble in Iran, I see. Hmm. Iran. Iran so far...   \n",
       "497     captain_pete  Reading the tweets coming out of Iran... The w...   \n",
       "\n",
       "                                          cleaned_text  \\\n",
       "0    loooooooovvvvvveee kindle2 dx cool 2 fantastic...   \n",
       "1            reading kindle2 love lee childs good read   \n",
       "2             ok first assesment kindle2 fucking rocks   \n",
       "3    love kindle2 mine months never looked back new...   \n",
       "4                    fair enough kindle2 think perfect   \n",
       "5                              big quite happy kindle2   \n",
       "6           fuck economy hate aig non loan given asses   \n",
       "7                               jquery new best friend   \n",
       "8                                        loves twitter   \n",
       "9                               love obama makes jokes   \n",
       "10   check video president obama white house corres...   \n",
       "11   firmly believe obama pelosi zero desire civil ...   \n",
       "12   house correspondents dinner last night whoopi ...   \n",
       "13   watchin espn jus seen new nike commerical pupp...   \n",
       "14   dear nike stop flywire shit waste science ugly...   \n",
       "15   lebron best athlete generation time basketball...   \n",
       "16   talking guy last night telling die hard spurs ...   \n",
       "17                                         love lebron   \n",
       "18               lebron beast still cheering 4 til end   \n",
       "19                                         lebron boss   \n",
       "20   lebron hometown hero lol love lakers let go ca...   \n",
       "21                         lebron zydrunas awesome duo   \n",
       "22            lebron beast nobody nba comes even close   \n",
       "23   downloading apps iphone much fun literally app...   \n",
       "24   good news call visa office saying everything f...   \n",
       "25                awesome come back biz via fredwilson   \n",
       "26           montreal long weekend r amp r much needed   \n",
       "27   booz allen hamilton bad ass homegrown social c...   \n",
       "28   mluc09 customer innovation award winner booz a...   \n",
       "29   current use nikon d90 love much canon 40d 50d ...   \n",
       "..                                                 ...   \n",
       "468  man kinda dislike apple right case point iphon...   \n",
       "469  kindle2 amp sony prs 500 like physical device ...   \n",
       "470         kindle2 seems best ereader work uk get one   \n",
       "471  google addiction thank pointing annamartin123 ...   \n",
       "472                   primary debit card visa electron   \n",
       "473                    bank get new visa platinum card   \n",
       "474  dearest google rich bastards visa card sent wo...   \n",
       "475             date bobby flay gut fieri food network   \n",
       "476  excited seeing bobby flay guy fieri tomorrow g...   \n",
       "477  gonna go see bobby flay 2moro shoreline eat dr...   \n",
       "478  wait great american food music festival shorel...   \n",
       "479  dad ny day ate mesa grill last night met bobby...   \n",
       "480                                     fighting latex   \n",
       "481                          love want die latex devil   \n",
       "482  7 hours 7 hours inkscape crashing normally sol...   \n",
       "483                            track iran social media   \n",
       "484  shit hitting fan iran craziness indeed iranele...   \n",
       "485  monday already iran may implode kitchen disast...   \n",
       "486  twitter stock buzz aapl es f spy spx palm upda...   \n",
       "487  getting ready test burger receipes weekend bob...   \n",
       "488                                 bobby flay joining   \n",
       "489  lam love bobby flay favorite rt terrysimpson b...   \n",
       "490  created first latex file scratch work well see...   \n",
       "491  using linux loving much nicer windows looking ...   \n",
       "492  using latex lot typeset mathematics looks hideous   \n",
       "493  ask programming latex indesign submitted calci...   \n",
       "494  note hate word hate pages hate latex said hate...   \n",
       "495  ahhh back real text editing environment lt 3 l...   \n",
       "496  trouble iran see hmm iran iran far away flocko...   \n",
       "497  reading tweets coming iran whole thing terrify...   \n",
       "\n",
       "                                              all_dict  SENTIMENT_VALUE  \\\n",
       "0    {'neg': 0.31, 'neu': 0.233, 'pos': 0.457, 'com...                4   \n",
       "1    {'neg': 0.0, 'neu': 0.413, 'pos': 0.587, 'comp...                4   \n",
       "2    {'neg': 0.0, 'neu': 0.694, 'pos': 0.306, 'comp...                4   \n",
       "3    {'neg': 0.113, 'neu': 0.538, 'pos': 0.349, 'co...                4   \n",
       "4    {'neg': 0.0, 'neu': 0.333, 'pos': 0.667, 'comp...                4   \n",
       "5    {'neg': 0.0, 'neu': 0.429, 'pos': 0.571, 'comp...                4   \n",
       "6    {'neg': 0.545, 'neu': 0.455, 'pos': 0.0, 'comp...                0   \n",
       "7    {'neg': 0.0, 'neu': 0.213, 'pos': 0.787, 'comp...                4   \n",
       "8    {'neg': 0.0, 'neu': 0.213, 'pos': 0.787, 'comp...                4   \n",
       "9    {'neg': 0.0, 'neu': 0.244, 'pos': 0.756, 'comp...                4   \n",
       "10   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "11   {'neg': 0.212, 'neu': 0.545, 'pos': 0.242, 'co...                0   \n",
       "12   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "13   {'neg': 0.0, 'neu': 0.602, 'pos': 0.398, 'comp...                4   \n",
       "14   {'neg': 0.524, 'neu': 0.176, 'pos': 0.3, 'comp...                0   \n",
       "15   {'neg': 0.0, 'neu': 0.645, 'pos': 0.355, 'comp...                4   \n",
       "16   {'neg': 0.4, 'neu': 0.488, 'pos': 0.112, 'comp...                0   \n",
       "17   {'neg': 0.0, 'neu': 0.192, 'pos': 0.808, 'comp...                4   \n",
       "18   {'neg': 0.0, 'neu': 0.602, 'pos': 0.398, 'comp...                4   \n",
       "19   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "20   {'neg': 0.0, 'neu': 0.309, 'pos': 0.691, 'comp...                4   \n",
       "21   {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...                4   \n",
       "22   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "23   {'neg': 0.0, 'neu': 0.68, 'pos': 0.32, 'compou...                4   \n",
       "24   {'neg': 0.439, 'neu': 0.244, 'pos': 0.317, 'co...                0   \n",
       "25   {'neg': 0.0, 'neu': 0.549, 'pos': 0.451, 'comp...                4   \n",
       "26   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "27   {'neg': 0.0, 'neu': 0.552, 'pos': 0.448, 'comp...                4   \n",
       "28   {'neg': 0.0, 'neu': 0.336, 'pos': 0.664, 'comp...                4   \n",
       "29   {'neg': 0.129, 'neu': 0.645, 'pos': 0.226, 'co...                4   \n",
       "..                                                 ...              ...   \n",
       "468  {'neg': 0.126, 'neu': 0.601, 'pos': 0.273, 'co...                4   \n",
       "469  {'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'comp...                4   \n",
       "470  {'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'comp...                4   \n",
       "471  {'neg': 0.0, 'neu': 0.396, 'pos': 0.604, 'comp...                4   \n",
       "472  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "473  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "474  {'neg': 0.247, 'neu': 0.321, 'pos': 0.432, 'co...                4   \n",
       "475  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "476  {'neg': 0.0, 'neu': 0.629, 'pos': 0.371, 'comp...                4   \n",
       "477  {'neg': 0.0, 'neu': 0.775, 'pos': 0.225, 'comp...                4   \n",
       "478  {'neg': 0.0, 'neu': 0.472, 'pos': 0.528, 'comp...                4   \n",
       "479  {'neg': 0.118, 'neu': 0.731, 'pos': 0.151, 'co...                4   \n",
       "480  {'neg': 0.714, 'neu': 0.286, 'pos': 0.0, 'comp...                0   \n",
       "481  {'neg': 0.561, 'neu': 0.068, 'pos': 0.372, 'co...                0   \n",
       "482  {'neg': 0.125, 'neu': 0.764, 'pos': 0.111, 'co...                0   \n",
       "483  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "484  {'neg': 0.496, 'neu': 0.32, 'pos': 0.184, 'com...                0   \n",
       "485  {'neg': 0.154, 'neu': 0.449, 'pos': 0.397, 'co...                4   \n",
       "486  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "487  {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'comp...                4   \n",
       "488  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "489  {'neg': 0.0, 'neu': 0.469, 'pos': 0.531, 'comp...                4   \n",
       "490  {'neg': 0.0, 'neu': 0.523, 'pos': 0.477, 'comp...                4   \n",
       "491  {'neg': 0.0, 'neu': 0.595, 'pos': 0.405, 'comp...                4   \n",
       "492  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "493  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "494  {'neg': 0.709, 'neu': 0.291, 'pos': 0.0, 'comp...                0   \n",
       "495  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...                2   \n",
       "496  {'neg': 0.252, 'neu': 0.748, 'pos': 0.0, 'comp...                0   \n",
       "497  {'neg': 0.503, 'neu': 0.497, 'pos': 0.0, 'comp...                0   \n",
       "\n",
       "    SENTIMENT  \n",
       "0    Positive  \n",
       "1    Positive  \n",
       "2    Positive  \n",
       "3    Positive  \n",
       "4    Positive  \n",
       "5    Positive  \n",
       "6    Negative  \n",
       "7    Positive  \n",
       "8    Positive  \n",
       "9    Positive  \n",
       "10    Neutral  \n",
       "11   Negative  \n",
       "12    Neutral  \n",
       "13   Positive  \n",
       "14   Negative  \n",
       "15   Positive  \n",
       "16   Negative  \n",
       "17   Positive  \n",
       "18   Positive  \n",
       "19    Neutral  \n",
       "20   Positive  \n",
       "21   Positive  \n",
       "22    Neutral  \n",
       "23   Positive  \n",
       "24   Negative  \n",
       "25   Positive  \n",
       "26    Neutral  \n",
       "27   Positive  \n",
       "28   Positive  \n",
       "29   Positive  \n",
       "..        ...  \n",
       "468  Positive  \n",
       "469  Positive  \n",
       "470  Positive  \n",
       "471  Positive  \n",
       "472   Neutral  \n",
       "473   Neutral  \n",
       "474  Positive  \n",
       "475   Neutral  \n",
       "476  Positive  \n",
       "477  Positive  \n",
       "478  Positive  \n",
       "479  Positive  \n",
       "480  Negative  \n",
       "481  Negative  \n",
       "482  Negative  \n",
       "483   Neutral  \n",
       "484  Negative  \n",
       "485  Positive  \n",
       "486   Neutral  \n",
       "487  Positive  \n",
       "488   Neutral  \n",
       "489  Positive  \n",
       "490  Positive  \n",
       "491  Positive  \n",
       "492   Neutral  \n",
       "493   Neutral  \n",
       "494  Negative  \n",
       "495   Neutral  \n",
       "496  Negative  \n",
       "497  Negative  \n",
       "\n",
       "[498 rows x 10 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find accuracy\n",
    "counter = 0\n",
    "for i in range(0,len(df_test)):\n",
    "    if (abs(df_test['sentiment'][i]-df_test['SENTIMENT_VALUE'][i])>1):\n",
    "        counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (df_test.shape[0]-counter)/df_test.shape[0]\n",
    "percent_accuracy = accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.27710843373494"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cjhutto/vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_VALUE = []\n",
    "SENTIMENT = []\n",
    "for i in range(0,len(df_test)):\n",
    "    sent = all_sent_values[i]['compound']\n",
    "    if (sent>=0.5):\n",
    "        SENTIMENT.append('Positive')\n",
    "        SENTIMENT_VALUE.append(4)\n",
    "    elif (sent>-0.5 and sent<0.5):\n",
    "        SENTIMENT.append('Neutral')\n",
    "        SENTIMENT_VALUE.append(2)\n",
    "    else:\n",
    "        SENTIMENT.append('Negative')\n",
    "        SENTIMENT_VALUE.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['SENTIMENT_VALUE'] = SENTIMENT_VALUE\n",
    "df_test['SENTIMENT'] = SENTIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find accuracy\n",
    "counter = 0\n",
    "for i in range(0,len(df_test)):\n",
    "    if (abs(df_test['sentiment'][i]-df_test['SENTIMENT_VALUE'][i])>1):\n",
    "        counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.831325301204814"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (df_test.shape[0]-counter)/df_test.shape[0]\n",
    "percent_accuracy = accuracy*100\n",
    "percent_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
